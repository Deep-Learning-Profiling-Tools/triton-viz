{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05199f6b-13f0-49af-9a57-d4e98f80ef47",
   "metadata": {},
   "source": [
    "# Triton Puzzles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88e71c24-2a2b-4616-9581-4f93eeb2a8f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 162) (draw.py, line 162)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[1;32m~/Projects/triton-viz/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3577\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[1;32mIn[1], line 5\u001b[0m\n    import triton_viz\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m~/Projects/triton-viz/triton_viz/__init__.py:2\u001b[0;36m\n\u001b[0;31m    from .draw import collect_grid, draw_record\u001b[0;36m\n",
      "\u001b[0;36m  File \u001b[0;32m~/Projects/triton-viz/triton_viz/draw.py:162\u001b[0;36m\u001b[0m\n\u001b[0;31m    es\"\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 162)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import triton\n",
    "from torch import Tensor\n",
    "import triton.language as tl\n",
    "import triton_viz\n",
    "from triton_viz.interpreter import record_builder\n",
    "import jaxtyping \n",
    "import inspect\n",
    "from jaxtyping import Float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a99c901-80db-482c-b734-d8e262540a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(puzzle, puzzle_spec, nelem={}, B={\"B0\": 128}):\n",
    "    B = dict(B)\n",
    "    if \"N1\" in nelem:\n",
    "        B[\"B1\"] = 128\n",
    "    if \"N2\" in nelem:\n",
    "        B[\"B2\"] = 128\n",
    "        \n",
    "    triton_viz.interpreter.record_builder.reset()\n",
    "    torch.manual_seed(0)\n",
    "    signature = inspect.signature(puzzle_spec)\n",
    "    args = {}\n",
    "    for n, p in signature.parameters.items():\n",
    "        args[n + \"_ptr\"] = [d.size for d in p.annotation.dims]\n",
    "    args[\"z_ptr\"] = [d.size for d in signature.return_annotation.dims]\n",
    "    \n",
    "    tt_args = []\n",
    "    for k, v in args.items():\n",
    "        tt_args.append(torch.rand(*v))\n",
    "    grid = lambda meta: (triton.cdiv(nelem[\"N0\"], meta[\"B0\"]), \n",
    "                         triton.cdiv(nelem.get(\"N1\", 1), meta.get(\"B1\", 1)), \n",
    "                         triton.cdiv(nelem.get(\"N2\", 1), meta.get(\"B2\", 1)))   \n",
    "    triton_viz.trace(puzzle)[grid](*tt_args, **B, **nelem)\n",
    "    z = tt_args[-1]\n",
    "    tt_args = tt_args[:-1]\n",
    "    z_ = puzzle_spec(*tt_args)\n",
    "    print(\"Results match:\",  torch.allclose(z, z_))\n",
    "    triton_viz.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f617b944-cf73-4bad-b7d6-1cc6d17879a9",
   "metadata": {},
   "source": [
    "## Puzzle 1: Constant Add\n",
    "\n",
    "Add a constant to a vector. Uses one program block. Block size `B0` is always the same as vector length `N0`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5fdae5-156e-48e6-abb3-9abe9d258229",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_spec(x: Float[Tensor, \"128\"]) -> Float[Tensor, \"128\"]:\n",
    "    return x + 10.\n",
    "\n",
    "@triton.jit\n",
    "def add_kernel(x_ptr, z_ptr, N0, B0: tl.constexpr):\n",
    "    range = tl.arange(0, B0)\n",
    "    x = tl.load(x_ptr + range)\n",
    "    z = x + 10\n",
    "    z = tl.store(z_ptr + range, z)\n",
    "\n",
    "test(add_kernel, add_spec, nelem={\"N0\": 128})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863aa741-98ba-4370-970a-7378a075fadb",
   "metadata": {},
   "source": [
    "## Puzzle 2: Constant Add Block\n",
    "\n",
    "Add a constant to a vector. Uses one program block. Block size `B0` is always the same as vector length `N0`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74baeaed-82d0-4814-b1fc-e9a51237cf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add2_spec(x: Float[Tensor, \"200\"]) -> Float[Tensor, \"200\"]:\n",
    "    return x + 10.\n",
    "\n",
    "@triton.jit\n",
    "def add_mask2_kernel(x_ptr, z_ptr, N0, B0: tl.constexpr):\n",
    "    pid = tl.program_id(0)\n",
    "    range = pid * B0 + tl.arange(0, B0)\n",
    "    x = tl.load(x_ptr + range, range < N0, 0\n",
    "               )\n",
    "    z = x + 10\n",
    "    z = tl.store(z_ptr + range, \n",
    "                 z, range < N0)\n",
    "    \n",
    "test(add_mask2_kernel, add2_spec, nelem={\"N0\": 200})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639dbf91-18b1-4bc6-8624-609b1031e9e1",
   "metadata": {},
   "source": [
    "## Puzzle 3: Outer Vector Add\n",
    "\n",
    "Add two vectors. Uses one program block. Block size `B0` is always the same as vector `x` length `N0`.\n",
    "Block size `B1` is always the same as vector `y` length `N1`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a977409-3fcb-4b72-abee-f09d02bf6f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_vec_spec(x: Float[Tensor, \"128\"], y: Float[Tensor, \"128\"]) -> Float[Tensor, \"128 128\"]:\n",
    "    return x[None, :] + y[:, None]\n",
    "\n",
    "@triton.jit\n",
    "def add_vec_kernel(x_ptr, y_ptr, z_ptr, N0, N1, B0: tl.constexpr, B1: tl.constexpr):\n",
    "    i_range = tl.arange(0, B0)[None, :] \n",
    "    j_range = tl.arange(0, B1)[:, None]\n",
    "    \n",
    "    x = tl.load(x_ptr + i_range)\n",
    "    y = tl.load(y_ptr + j_range)\n",
    "    \n",
    "    z = x + y\n",
    "    z = tl.store(z_ptr + i_range + B0 * j_range, z)\n",
    "    \n",
    "test(add_vec_kernel, add_vec_spec, nelem={\"N0\": 128, \"N1\": 128})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea0bd06-58f5-4088-af2a-f3c0d80f5e15",
   "metadata": {},
   "source": [
    "## Puzzle 4: Outer Vector Add Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbbe277-344b-4750-b9aa-f7b7da6303d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_vec_spec(x: Float[Tensor, \"i j\"], i: int) -> Float[Tensor, \"i\"]:\n",
    "    return x + 10.\n",
    "\n",
    "@triton_viz.trace\n",
    "@triton.jit\n",
    "def add_vec_kernel(x_ptr, y_ptr, z_ptr, B0: tl.constexpr, B1: tl.constexpr):\n",
    "    pid_0 = tl.program_id(0)\n",
    "    pid_1 = tl.program_id(1)\n",
    "\n",
    "    i_range = tl.arange(0, BLOCK_SIZE)[:, None] + pid_0 * B0\n",
    "    j_range = tl.arange(0, BLOCK_SIZE)[None, :] + pid_1 * B1\n",
    "    \n",
    "    x = tl.load(x_ptr + i_range)\n",
    "    y = tl.load(x_ptr + j_range)\n",
    "    \n",
    "    z = x + y\n",
    "    z = tl.store(z_ptr + i_range * B1 + j_range, \n",
    "                 z)\n",
    "    \n",
    "test(add_vec_kernel, add_vec_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025a1cfa-6b4e-4456-acc4-d15aa35ec605",
   "metadata": {},
   "source": [
    "## Puzzle 5: Fused Op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55955d0-b670-4dc4-9db1-5f28ce4f56fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e1677c8-a1e8-476c-bf04-8a6ba912c84d",
   "metadata": {},
   "source": [
    "## Puzzle 6: Fused Op Backwards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86402b17-9fa4-489b-8c79-71d4ecb68ff2",
   "metadata": {},
   "source": [
    "## Puzzle 7: Sum and Backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9a50fd-3774-420c-9fec-faac8fdcc7de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae12e14b-0da4-414c-9574-ab747b2be387",
   "metadata": {},
   "source": [
    "## Puzzle 8: Manual Conv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82214261-9c28-4d97-87e4-816c9cd4e6b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5750a41e-8abd-431d-9da8-0ef0ff9207df",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2a38d4-2595-4eae-b042-37172b21a0ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d2752542-0161-48e2-9efc-f7a730ebc2a6",
   "metadata": {},
   "source": [
    "## Puzzle 9: Matrix Mult"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8917111-6ceb-4491-9f7a-733dd4f29a04",
   "metadata": {},
   "source": [
    "## Puzzle 10: Quantized Matrix Mult "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1be37c-9666-4a78-a554-8dea74bf1642",
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton_viz.trace\n",
    "@triton.jit\n",
    "def dot_kernel(x_ptr, y_ptr, z_ptr, BLOCK_SIZE: tl.constexpr):\n",
    "    r = tl.program_id(0) * BLOCK_SIZE\n",
    "    c = tl.program_id(1) * BLOCK_SIZE\n",
    "    b = tl.program_id(2)\n",
    "    bid = b * 4 * BLOCK_SIZE * BLOCK_SIZE\n",
    "    x_val = tl.load(\n",
    "        x_ptr\n",
    "        + bid\n",
    "        + (r + tl.arange(0, BLOCK_SIZE)[:, None]) * 2 * BLOCK_SIZE\n",
    "        + tl.arange(0, BLOCK_SIZE)[None, :]\n",
    "    )\n",
    "    y_val = tl.load(\n",
    "        y_ptr\n",
    "        + bid\n",
    "        + tl.arange(0, BLOCK_SIZE)[:, None] * 2 * BLOCK_SIZE\n",
    "        + tl.arange(0, BLOCK_SIZE)[None, :]\n",
    "        + c\n",
    "    )\n",
    "    z = tl.dot(x_val, y_val)\n",
    "    x_val = tl.load(\n",
    "        x_ptr\n",
    "        + bid\n",
    "        + (r + tl.arange(0, BLOCK_SIZE)[:, None]) * 2 * BLOCK_SIZE\n",
    "        + tl.arange(0, BLOCK_SIZE)[None, :]\n",
    "        + BLOCK_SIZE\n",
    "    )\n",
    "    y_val = tl.load(\n",
    "        y_ptr\n",
    "        + bid\n",
    "        + (BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)[:, None]) * 2 * BLOCK_SIZE\n",
    "        + tl.arange(0, BLOCK_SIZE)[None, :]\n",
    "        + c\n",
    "    )\n",
    "    z = z + tl.dot(x_val, y_val)\n",
    "    tl.store(\n",
    "        z_ptr\n",
    "        + (b * (2 * BLOCK_SIZE) * (2 * BLOCK_SIZE - 10))\n",
    "        + (r + tl.arange(0, BLOCK_SIZE)[:, None]) * (2 * BLOCK_SIZE - 10)\n",
    "        + tl.arange(0, BLOCK_SIZE)[None, :]\n",
    "        + c,\n",
    "        z,\n",
    "        mask=tl.arange(0, BLOCK_SIZE)[None, :] + c < 2 * BLOCK_SIZE - 10,\n",
    "    )\n",
    "\n",
    "\n",
    "def perform_dot(device, BATCH, BLOCK_SIZE):\n",
    "    x = torch.randn((BATCH, 2 * BLOCK_SIZE, 2 * BLOCK_SIZE), device=device)\n",
    "    y = torch.randn((BATCH, 2 * BLOCK_SIZE, 2 * BLOCK_SIZE), device=device)\n",
    "    z = torch.zeros((BATCH, 2 * BLOCK_SIZE, 2 * BLOCK_SIZE - 10), device=device)\n",
    "    dot_kernel[(2, 2, BATCH)](x, y, z, BLOCK_SIZE)\n",
    "    return x, y, z\n",
    "BLOCK_SIZE = 32\n",
    "input_matrix1, input_matrix2, result = perform_dot(device, 12, BLOCK_SIZE)\n",
    "triton_viz.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2260031a-3f0a-4e67-a7b4-1be0bdef3b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton_viz.trace\n",
    "@triton.jit\n",
    "def add_kernel(X, Y, Z, n_elements,  # Size of the vector.  BLOCK_SIZE: tl.constexpr,  # Number of elements each program should process.\n",
    "    # NOTE: `constexpr` so it can be used as a shape value.\n",
    "):\n",
    "    pid = tl.program_id(axis=0)  # We use a 1D launch grid so axis is 0.\n",
    "    # This program will process inputs that are offset from the initial data.\n",
    "    # For instance, if you had a vector of length 256 and block_size of 64, the programs\n",
    "    # would each access the elements [0:64, 64:128, 128:192, 192:256].\n",
    "    # Note that offsets is a list of pointers:\n",
    "    block_start = pid * BLOCK_SIZE\n",
    "    offsets = block_start + tl.arange(0, BLOCK_SIZE)\n",
    "    # Create a mask to guard memory operations against out-of-bounds accesses.\n",
    "    mask = offsets < n_elements\n",
    "    # Load x and y from DRAM, masking out any extra elements in case the input is not a\n",
    "    # multiple of the block size.\n",
    "    x = tl.load(x_ptr + offsets, mask=mask)\n",
    "    y = tl.load(y_ptr + offsets, mask=mask)\n",
    "    output = x + y\n",
    "    # Write x + y back to DRAM.\n",
    "    tl.store(output_ptr + offsets, output, mask=mask)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f05f927-e1bd-4baa-bbb5-6f8583f9145c",
   "metadata": {},
   "source": [
    "## Puzzle 2: Blocking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17d73ca-6b68-4222-b842-125ec2b0955a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton_viz.trace\n",
    "@triton.jit\n",
    "def add_kernel(\n",
    "    x_ptr,  # *Pointer* to first input vector.\n",
    "    y_ptr,  # *Pointer* to second input vector.\n",
    "    output_ptr,  # *Pointer* to output vector.\n",
    "    n_elements,  # Size of the vector.\n",
    "    BLOCK_SIZE: tl.constexpr,  # Number of elements each program should process.\n",
    "    # NOTE: `constexpr` so it can be used as a shape value.\n",
    "):\n",
    "    pid = tl.program_id(axis=0)  # We use a 1D launch grid so axis is 0.\n",
    "    # This program will process inputs that are offset from the initial data.\n",
    "    # For instance, if you had a vector of length 256 and block_size of 64, the programs\n",
    "    # would each access the elements [0:64, 64:128, 128:192, 192:256].\n",
    "    # Note that offsets is a list of pointers:\n",
    "    block_start = pid * BLOCK_SIZE\n",
    "    offsets = block_start + tl.arange(0, BLOCK_SIZE)\n",
    "    # Create a mask to guard memory operations against out-of-bounds accesses.\n",
    "    mask = offsets < n_elements\n",
    "    # Load x and y from DRAM, masking out any extra elements in case the input is not a\n",
    "    # multiple of the block size.\n",
    "    x = tl.load(x_ptr + offsets, mask=mask)\n",
    "    y = tl.load(y_ptr + offsets, mask=mask)\n",
    "    output = x + y\n",
    "    # Write x + y back to DRAM.\n",
    "    tl.store(output_ptr + offsets, output, mask=mask)\n",
    "\n",
    "\n",
    "def add(x: torch.Tensor, y: torch.Tensor):\n",
    "    # We need to preallocate the output.\n",
    "    output = torch.empty_like(x)\n",
    "    n_elements = output.numel()\n",
    "    # The SPMD launch grid denotes the number of kernel instances that run in parallel.\n",
    "    # It is analogous to CUDA launch grids. It can be either Tuple[int], or Callable(metaparameters) -> Tuple[int].\n",
    "    # In this case, we use a 1D grid where the size is the number of blocks:\n",
    "    grid = lambda meta: (triton.cdiv(n_elements, meta[\"BLOCK_SIZE\"]),)\n",
    "    # NOTE:\n",
    "    #  - Each torch.tensor object is implicitly converted into a pointer to its first element.\n",
    "    #  - `triton.jit`'ed functions can be indexed with a launch grid to obtain a callable GPU kernel.\n",
    "    #  - Don't forget to pass meta-parameters as keywords arguments.\n",
    "    add_kernel[grid](x, y, output, n_elements, BLOCK_SIZE=1024)\n",
    "    # We return a handle to z but, since `torch.cuda.synchronize()` hasn't been called, the kernel is still\n",
    "    # running asynchronously at this point.\n",
    "    return output, grid\n",
    "\n",
    "    # Directly use x and y here even though they are defined later in the file\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e3fa4a-a938-491b-a208-055e58ce1137",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "size = 5000\n",
    "input_vector1, input_vector2, output_triton = perform_vec_add(device, size)\n",
    "triton_viz.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8f99fa-0d46-4ffd-bc2d-b294b6bfde31",
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton_viz.trace\n",
    "@triton.jit\n",
    "def dot_kernel(x_ptr, y_ptr, z_ptr, BLOCK_SIZE: tl.constexpr):\n",
    "    r = tl.program_id(0) * BLOCK_SIZE\n",
    "    c = tl.program_id(1) * BLOCK_SIZE\n",
    "    b = tl.program_id(2)\n",
    "    bid = b * 4 * BLOCK_SIZE * BLOCK_SIZE\n",
    "    x_val = tl.load(\n",
    "        x_ptr\n",
    "        + bid\n",
    "        + (r + tl.arange(0, BLOCK_SIZE)[:, None]) * 2 * BLOCK_SIZE\n",
    "        + tl.arange(0, BLOCK_SIZE)[None, :]\n",
    "    )\n",
    "    y_val = tl.load(\n",
    "        y_ptr\n",
    "        + bid\n",
    "        + tl.arange(0, BLOCK_SIZE)[:, None] * 2 * BLOCK_SIZE\n",
    "        + tl.arange(0, BLOCK_SIZE)[None, :]\n",
    "        + c\n",
    "    )\n",
    "    z = tl.dot(x_val, y_val)\n",
    "    x_val = tl.load(\n",
    "        x_ptr\n",
    "        + bid\n",
    "        + (r + tl.arange(0, BLOCK_SIZE)[:, None]) * 2 * BLOCK_SIZE\n",
    "        + tl.arange(0, BLOCK_SIZE)[None, :]\n",
    "        + BLOCK_SIZE\n",
    "    )\n",
    "    y_val = tl.load(\n",
    "        y_ptr\n",
    "        + bid\n",
    "        + (BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)[:, None]) * 2 * BLOCK_SIZE\n",
    "        + tl.arange(0, BLOCK_SIZE)[None, :]\n",
    "        + c\n",
    "    )\n",
    "    z = z + tl.dot(x_val, y_val)\n",
    "    tl.store(\n",
    "        z_ptr\n",
    "        + (b * (2 * BLOCK_SIZE) * (2 * BLOCK_SIZE - 10))\n",
    "        + (r + tl.arange(0, BLOCK_SIZE)[:, None]) * (2 * BLOCK_SIZE - 10)\n",
    "        + tl.arange(0, BLOCK_SIZE)[None, :]\n",
    "        + c,\n",
    "        z,\n",
    "        mask=tl.arange(0, BLOCK_SIZE)[None, :] + c < 2 * BLOCK_SIZE - 10,\n",
    "    )\n",
    "\n",
    "\n",
    "def perform_dot(device, BATCH, BLOCK_SIZE):\n",
    "    x = torch.randn((BATCH, 2 * BLOCK_SIZE, 2 * BLOCK_SIZE), device=device)\n",
    "    y = torch.randn((BATCH, 2 * BLOCK_SIZE, 2 * BLOCK_SIZE), device=device)\n",
    "    z = torch.zeros((BATCH, 2 * BLOCK_SIZE, 2 * BLOCK_SIZE - 10), device=device)\n",
    "    dot_kernel[(2, 2, BATCH)](x, y, z, BLOCK_SIZE)\n",
    "    return x, y, z\n",
    "BLOCK_SIZE = 32\n",
    "input_matrix1, input_matrix2, result = perform_dot(device, 12, BLOCK_SIZE)\n",
    "triton_viz.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tritonviz",
   "language": "python",
   "name": "tritonviz"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
